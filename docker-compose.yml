services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: ppt-translate-backend
    ports:
      - "5001:5001"
    extra_hosts:
      # 讓容器可以連接到本機服務 (包括本機 Ollama)
      - "host.docker.internal:host-gateway"
    environment:
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - TRANSLATE_LLM_MODE=${TRANSLATE_LLM_MODE:-real}
      # 連接本機 Ollama (使用 host.docker.internal)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-translategemma:4b}
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-180}
      - OLLAMA_NUM_CTX=${OLLAMA_NUM_CTX:-8192}
      # Gemini Configuration
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GEMINI_BASE_URL=${GEMINI_BASE_URL:-https://generativelanguage.googleapis.com/v1beta}
      - GEMINI_TIMEOUT=${GEMINI_TIMEOUT:-180}
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_TIMEOUT=${OPENAI_TIMEOUT:-60}
      # SiliconFlow Configuration
      - SILICONFLOW_API_KEY=${SILICONFLOW_API_KEY:-}
      - SILICONFLOW_MODEL=${SILICONFLOW_MODEL:-Qwen/Qwen2.5-7B-Instruct}
      - SILICONFLOW_BASE_URL=${SILICONFLOW_BASE_URL:-https://api.siliconflow.cn/v1}
      # Translation Settings
      - SOURCE_LANGUAGE=${SOURCE_LANGUAGE:-auto}
      - LLM_CONTEXT_STRATEGY=${LLM_CONTEXT_STRATEGY:-none}
      - LLM_GLOSSARY_PATH=${LLM_GLOSSARY_PATH:-}
      - LLM_FALLBACK_ON_ERROR=${LLM_FALLBACK_ON_ERROR:-0}
      - LLM_SINGLE_REQUEST=${LLM_SINGLE_REQUEST:-1}
      - LLM_CHUNK_SIZE=${LLM_CHUNK_SIZE:-50}
      - LLM_MAX_RETRIES=${LLM_MAX_RETRIES:-3}
      - LLM_RETRY_BACKOFF=${LLM_RETRY_BACKOFF:-0.8}
      - LLM_RETRY_MAX_BACKOFF=${LLM_RETRY_MAX_BACKOFF:-8}
      - LLM_CHUNK_DELAY=${LLM_CHUNK_DELAY:-0}
      - CORS_ORIGIN=${CORS_ORIGIN:-*}
    volumes:
      - ./data:/app/data
      - ./backend:/app/backend
      - ./docs:/app/docs
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5001/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    command: uvicorn backend.main:app --host 0.0.0.0 --port 5001 --reload
    develop:
      watch:
        - action: sync
          path: ./backend
          target: /app/backend
          ignore:
            - __pycache__
            - .pytest_cache

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: ppt-translate-frontend
    ports:
      - "5193:80"
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./frontend:/app/frontend
    develop:
      watch:
        - action: rebuild
          path: ./frontend/src
        - action: rebuild
          path: ./frontend/public
    restart: unless-stopped

networks:
  default:
    name: ppt-translate-network
